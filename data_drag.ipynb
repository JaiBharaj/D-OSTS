{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b4243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to tle_json\\last_30_days.json, total 163 records\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Target URL\n",
    "url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=last-30-days&FORMAT=json'\n",
    "\n",
    "# Local save directory\n",
    "out_dir = 'tle_json'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, 'last_30_days.json')\n",
    "\n",
    "# 1. Send request\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status()  # Raises an exception if the response status is not 200\n",
    "\n",
    "# 2. Parse into a Python object (list/dict)\n",
    "data = resp.json()\n",
    "\n",
    "# 3. Write to local file\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    # indent=2 for readability, ensure_ascii=False to retain Unicode characters\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f'Saved to {out_path}, total {len(data)} records')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a417b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 163 state vectors and saved to last_30_days_state_vectors_corrected.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# compute_state_vectors.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from poliastro.bodies import Earth\n",
    "from poliastro.twobody.orbit import Orbit\n",
    "\n",
    "# Input JSON file path\n",
    "INPUT_JSON = 'tle_json/last_30_days.json'\n",
    "# Output CSV file path\n",
    "OUTPUT_CSV = 'last_30_days_state_vectors_corrected.csv'\n",
    "\n",
    "def main():\n",
    "    # 1. Load GP JSON data\n",
    "    with open(INPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "        sats = json.load(f)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for sat in sats:\n",
    "        name = sat.get('OBJECT_NAME', 'UNKNOWN')\n",
    "        epoch_str = sat['EPOCH']  # ISO-format timestamp\n",
    "        epoch = Time(epoch_str, format='isot', scale='utc')\n",
    "\n",
    "        # 2. Classical orbital elements (from the GP JSON fields)\n",
    "        inc  = sat['INCLINATION']        * u.deg\n",
    "        raan = sat['RA_OF_ASC_NODE']     * u.deg\n",
    "        ecc  = sat['ECCENTRICITY']       * u.one\n",
    "        argp = sat['ARG_OF_PERICENTER']  * u.deg\n",
    "        M    = sat['MEAN_ANOMALY']       * u.deg\n",
    "\n",
    "        # 3. Convert mean motion from rev/day → rad/s\n",
    "        #    sat['MEAN_MOTION'] is given in rev/day\n",
    "        mean_motion_rev_per_day = sat['MEAN_MOTION'] * u.one / u.day\n",
    "        # Convert to 1/s, then multiply by 2π to get rad/s\n",
    "        n_rad_s = mean_motion_rev_per_day.to(1 / u.s) * (2 * np.pi)\n",
    "\n",
    "        # 4. Compute semi-major axis a (km) from Kepler's third law\n",
    "        mu = Earth.k.to(u.km**3 / u.s**2)\n",
    "        a = (mu / n_rad_s**2) ** (1/3)\n",
    "\n",
    "        # 5. Solve for eccentric anomaly E, then compute true anomaly ν\n",
    "        M_rad = M.to(u.rad).value\n",
    "        e = ecc.value\n",
    "        E = M_rad  # Initial guess\n",
    "        for _ in range(100):\n",
    "            E = E - (E - e * np.sin(E) - M_rad) / (1 - e * np.cos(E))\n",
    "        nu = 2 * np.arctan2(\n",
    "            np.sqrt(1 + e) * np.sin(E / 2),\n",
    "            np.sqrt(1 - e) * np.cos(E / 2)\n",
    "        ) * u.rad\n",
    "\n",
    "        # 6. Build the Orbit and extract the state vector\n",
    "        orb = Orbit.from_classical(\n",
    "            attractor=Earth,\n",
    "            a=a,\n",
    "            ecc=ecc,\n",
    "            inc=inc,\n",
    "            raan=raan,\n",
    "            argp=argp,\n",
    "            nu=nu,\n",
    "            epoch=epoch\n",
    "        )\n",
    "        r_vec = orb.r.to(u.km).value     # [x, y, z] in km\n",
    "        v_vec = orb.v.to(u.km / u.s).value  # [vx, vy, vz] in km/s\n",
    "\n",
    "        records.append({\n",
    "            'OBJECT_NAME': name,\n",
    "            'EPOCH':       epoch_str,\n",
    "            'x_km':        r_vec[0],\n",
    "            'y_km':        r_vec[1],\n",
    "            'z_km':        r_vec[2],\n",
    "            'vx_km_s':     v_vec[0],\n",
    "            'vy_km_s':     v_vec[1],\n",
    "            'vz_km_s':     v_vec[2],\n",
    "        })\n",
    "\n",
    "    # 7. Save results\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f'✅ Generated {len(df)} state vectors and saved to {OUTPUT_CSV}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# If you need to inspect the first few rows after running:\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv(OUTPUT_CSV)\n",
    "# print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318b0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated file with radial/transverse velocities: state_vectors_rt.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Input CSV: contains state vectors x, y, z, vx, vy, vz\n",
    "input_csv = 'last_30_days_state_vectors_corrected.csv'\n",
    "# Output CSV: will include additional columns v_r_km_s and v_t_km_s\n",
    "output_csv = 'state_vectors_rt.csv'\n",
    "\n",
    "# 1. Read the data\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# 2. Compute radial and transverse velocities\n",
    "def compute_rt_velocities(row):\n",
    "    # Position vector\n",
    "    r = np.array([row['x_km'], row['y_km'], row['z_km']])\n",
    "    # Velocity vector\n",
    "    v = np.array([row['vx_km_s'], row['vy_km_s'], row['vz_km_s']])\n",
    "    # Unit radial vector\n",
    "    r_hat = r / np.linalg.norm(r)\n",
    "    # Radial velocity = v · r_hat\n",
    "    v_r = np.dot(v, r_hat)\n",
    "    # Transverse velocity vector = v - v_r * r_hat\n",
    "    v_t_vec = v - v_r * r_hat\n",
    "    # Transverse speed magnitude\n",
    "    v_t = np.linalg.norm(v_t_vec)\n",
    "    return pd.Series({'v_r_km_s': v_r, 'v_t_km_s': v_t})\n",
    "\n",
    "# Apply to each row and concatenate the new columns\n",
    "rt = df.apply(compute_rt_velocities, axis=1)\n",
    "df = pd.concat([df, rt], axis=1)\n",
    "\n",
    "# 3. Save the results\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f'✅ Generated file with radial/transverse velocities: {output_csv}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7191a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
